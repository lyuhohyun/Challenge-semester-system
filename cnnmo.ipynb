{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3364939,"sourceType":"datasetVersion","datasetId":2029496},{"sourceId":11240501,"sourceType":"datasetVersion","datasetId":7022703},{"sourceId":11400397,"sourceType":"datasetVersion","datasetId":7140284}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 style=\"color: white; background-color: dodgerblue; font-weight: bold; text-align: center; border:3px solid black;\">Alzheimer MR Images Classification</h1>\n\n<div style=\"color: black; background-color: lightsteelblue; border:2px solid black;\">\n    <ul>\n        <p>6400 different MRIs (Magnetic Resonance Image) collected from different sources were given in this project. 6400 images belong to 4 different classes. These classes are as follows;</p>\n            <li>Mild Demented</li>\n            <li>Moderate Demented</li>\n            <li>Non Demented</li>\n            <li>Very Mild Demented</li>\n            <br>\n        <p>After examining the target value distribution, we will split the data into training, testing, and validation datasets. Next, we will create a model using Convolutional Neural Networks (CNN). After the model is trained, we will evaluate its performance by assessing how accurately it predicts previously unseen Magnetic Resonance Images.</p>\n    </ul>\n</div>","metadata":{}},{"cell_type":"markdown","source":"# Importing Necessary Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport seaborn as sns\nimport math\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport keras\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras import layers\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\n\nplt.rcParams[\"figure.figsize\"] = (10,6)\nplt.rcParams['figure.dpi'] = 300\ncolors = [\"#B6EE56\", \"#D85F9C\", \"#EEA756\", \"#56EEE8\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"try:\n    if tf.test.gpu_device_name():\n        physical_devices = tf.config.experimental.list_physical_devices('GPU')\n        print('GPU active! -', physical_devices)\n    else:\n        print('GPU not active!')\nexcept Exception as e:\n    print('An error occurred while checking the GPU:', e)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Target Value Distribution","metadata":{}},{"cell_type":"markdown","source":"<p style=\"color: black; background-color: lightsteelblue; border:2px solid black;\">Seeing the distribution of the target values is of critical importance in determining the methods to be applied in the subsequent steps. Therefore, let's first navigate to the data folder path and check the number of images in each class folder.</p>","metadata":{}},{"cell_type":"code","source":"class_dist = {}\ndef image_counter(folder_path):\n    basename = os.path.basename(folder_path)\n    print('\\033[92m'+f\"A search has been initiated within the folder named '{basename}'.\"+'\\033[0m')\n    image_extensions = ['.jpg', '.jpeg', '.png']\n\n    for root, dirs, _ in os.walk(folder_path):\n        for dir_name in dirs:\n            dir_path = os.path.join(root, dir_name)\n            count = 0\n\n            for filename in os.listdir(dir_path):\n                file_ext = os.path.splitext(filename)[1].lower()\n\n                if file_ext in image_extensions:\n                    count += 1\n            \n            class_dist[dir_name] = count\n            print(f\"There are \\033[35m{count}\\033[0m images in the {dir_name} folder.\")\n    print('\\033[92m'+\"The search has been completed.\"+'\\033[0m')\n    \n    keys = list(class_dist.keys())\n    values = list(class_dist.values())\n    explode = (0.1,)*len(keys)\n    \n    labels = [f'{key} ({value} images)' for key, value in zip(keys, values)]\n    \n    plt.pie(values, explode=explode,labels=labels, autopct='%1.1f%%',\n            shadow=True, startangle=90, colors=colors, textprops={'fontsize': 12, \"fontweight\" : \"bold\", \"color\":\"darkblue\"},  wedgeprops=\n           {'edgecolor':'darkblue'} , labeldistance=1.15)\n    plt.title(\"Distribution of \\nDementia MRI Images\", size=12, fontweight=\"bold\")\n\nPATH = '/kaggle/input/dementia2'\n\nimage_counter(PATH)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<p style=\"color: black; background-color: lightsteelblue; border:2px solid black;\">As observed in the class distribution, we have an imbalanced dataset. <b>Non Demented MRI class constitutes 50% of the total data with 3200 images</b>, while <b>Moderate Demented MRI class only makes up 1% of the dataset with 64 images.</b></p>","metadata":{}},{"cell_type":"markdown","source":"# Generate TF Dataset","metadata":{}},{"cell_type":"markdown","source":"<p style=\"color: black; background-color: lightsteelblue; border:2px solid black;\">When examining the data path, we can see that the folder named <b>\"Dataset\"</b> is the main folder, and within it, there are separate folders for each class containing their respective images.</p>\n\n<div style=\"color: black; background-color: lightsteelblue; border:2px solid black;\">\n<b>Dataset/</b>\n<br><b>...Mild_Demented/</b>\n<br>......mild_1.jpg\n<br>......mild_2.jpg\n<br><b>...Moderate_Demented/</b>\n<br>......moderate_1.jpg\n<br>......moderate_2.jpg\n<br>\n<br>\n<p>When encountering a situation with such a structure, TensorFlow has a powerful function <code>tf.keras.utils.image_dataset_from_directory</code> for reading data.</p>\n    \n</div>","metadata":{}},{"cell_type":"code","source":"data = tf.keras.utils.image_dataset_from_directory(PATH,\n                                                batch_size = 32,\n                                                image_size=(128, 128),\n                                                shuffle=True,\n                                                seed=42,)\n\nclass_names = data.class_names","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<p style=\"color: black; background-color: lightsteelblue; border:2px solid black;\">Let's see some samples for each class!</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\"color: white; background-color: dodgerblue; font-weight: bold; text-align: center; border:3px solid black;\">MRI Samples for Each Class</h2>","metadata":{}},{"cell_type":"code","source":"def sample_bringer(path, target, num_samples=5):\n    \n    class_path = os.path.join(path, target)\n\n    image_files = [image for image in os.listdir(class_path) if image.endswith('.jpg')]\n\n    fig, ax = plt.subplots(1, num_samples, facecolor=\"gray\")\n    fig.suptitle(f'{target} Brain MRI Samples', color=\"yellow\",fontsize=16, fontweight='bold', y=0.75)\n    \n    for i in range(num_samples):\n        image_path = os.path.join(class_path, image_files[i])\n        img = mpimg.imread(image_path)\n\n        ax[i].imshow(img)\n        ax[i].axis('off')\n        ax[i].set_title(f'Sample {i+1}', color=\"aqua\")\n\n    plt.tight_layout()\n    \nfor target in class_names:\n    sample_bringer(PATH, target=target)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<p style=\"color: black; background-color: lightsteelblue; border:2px solid black;\">Pixel normalization improves the performance of a neural network. Therefore, we will go with pixel values from 0 to 1, rather than values in the range 0 to 255.</p>","metadata":{}},{"cell_type":"code","source":"alz_dict = {index: img for index, img in enumerate(data.class_names)}\n\nclass Process:\n    def __init__(self, data):\n        self.data = data.map(lambda x, y: (x/255, y))\n\n    def create_new_batch(self):\n        self.batch = self.data.as_numpy_iterator().next()\n        text = \"Min and max pixel values in the batch ->\"\n        print(text, self.batch[0].min(), \"&\", self.batch[0].max())\n        \n    def show_batch_images(self, number_of_images=5):\n        fig, ax = plt.subplots(ncols=number_of_images, figsize=(20,20), facecolor=\"gray\")\n        fig.suptitle(\"Brain MRI (Dementia) Samples in the Batch\", color=\"yellow\",fontsize=18, fontweight='bold', y=0.6)\n        for idx, img in enumerate(self.batch[0][:number_of_images]):\n            ax[idx].imshow(img)\n            class_no = self.batch[1][idx]\n            ax[idx].set_title(alz_dict[class_no], color=\"aqua\")\n            ax[idx].set_xticklabels([])\n            ax[idx].set_yticklabels([])\n    \n    def train_test_val_split(self, train_size, val_size, test_size):\n\n        train = int(len(self.data)*train_size)\n        test = int(len(self.data)*test_size)\n        val = int(len(self.data)*val_size)\n        \n        train_data = self.data.take(train)\n        val_data = self.data.skip(train).take(val)\n        test_data = self.data.skip(train+val).take(test)\n\n        return train_data, val_data, test_data","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"process = Process(data)\nprocess.create_new_batch()\nprocess.show_batch_images(number_of_images=5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<p style=\"color: black; background-color: lightsteelblue; border:2px solid black;\">We will divide the dataset into 80% training data, 10% validation data and 10% test data.</p>","metadata":{}},{"cell_type":"code","source":"train_data, val_data, test_data= process.train_test_val_split(train_size=0.8, val_size=0.1, test_size=0.1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<p style=\"color: black; background-color: lightsteelblue; border:2px solid black;\">\nWe have an imbalanced distribution of target class. When dealing with an imbalanced target class distribution, using class weights can help the model perform better and effectively recognize the minority classes. Therefore, let's calculate the weights of the target classes in our training data and provide this information to our model during training.</p>","metadata":{}},{"cell_type":"code","source":"y_train = tf.concat(list(map(lambda x: x[1], train_data)), axis=0)\nclass_weight = compute_class_weight('balanced',classes=np.unique(y_train), y=y_train.numpy())\nclass_weights = dict(zip(np.unique(y_train), class_weight))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    \n    model.add(Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", kernel_initializer='he_normal',\n                     input_shape=(128, 128, 3)))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", kernel_initializer='he_normal'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    \n    model.add(Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), activation=\"relu\", kernel_initializer='he_normal'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n              \n    model.add(Flatten())\n    model.add(Dense(128, activation=\"relu\", kernel_initializer='he_normal'))\n    model.add(Dense(64, activation=\"relu\"))\n    model.add(Dense(4, activation=\"softmax\"))\n\n    model.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n\n     optimizer = Adam(learning_rate=0.001)\n\n    model.summary()\n    \n    return model\n\nmodel = build_model()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2 style=\"color: white; background-color: dodgerblue; font-weight: bold; text-align: center; border:3px solid black;\">Callbacks</h2>","metadata":{}},{"cell_type":"code","source":"def checkpoint_callback():\n    \n    checkpoint_filepath = '/tmp/checkpoint.keras'\n    \n    model_checkpoint_callback= ModelCheckpoint(filepath=checkpoint_filepath,\n                           save_weights_only=False,\n                           save_freq='epoch',\n                           monitor='val_accuracy',\n                           save_best_only=True,\n                           verbose=1)\n    \n    return model_checkpoint_callback\n\ndef early_stopping(patience):\n    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, verbose=1)\n    return es_callback\n\n\nEPOCHS = 20\ncheckpoint_callback = checkpoint_callback()\nearly_stopping = early_stopping(patience=5)\ncallbacks = [checkpoint_callback, early_stopping]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(train_data, epochs = EPOCHS, validation_data = val_data, class_weight = class_weights, callbacks = callbacks)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2 style=\"color: white; background-color: dodgerblue; font-weight: bold; text-align: center; border:3px solid black;\">Loss and Accuracy</h2>","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(12,6), facecolor=\"khaki\")\nax[0].set_facecolor('palegoldenrod')  \nax[0].set_title('Loss', fontweight=\"bold\")\nax[0].set_xlabel(\"Epoch\", size=14)\nax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train Loss\", color=\"navy\")\nax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation Loss\", color=\"crimson\", linestyle=\"dashed\")\nax[0].legend()\nax[1].set_facecolor('palegoldenrod')\nax[1].set_title('Accuracy', fontweight=\"bold\")\nax[1].set_xlabel(\"Epoch\", size=20)\nax[1].plot(history.epoch, history.history[\"accuracy\"], label=\"Train Acc.\", color=\"navy\")\nax[1].plot(history.epoch, history.history[\"val_accuracy\"], label=\"Validation Acc.\", color=\"crimson\", linestyle=\"dashed\")\nax[1].legend()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2 style=\"color: white; background-color: dodgerblue; font-weight: bold; text-align: center; border:3px solid black;\">Evaluating Test Data</h2>","metadata":{}},{"cell_type":"code","source":"model.evaluate(test_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2 style=\"color: white; background-color: dodgerblue; font-weight: bold; text-align: center; border:3px solid black;\">Classification Report</h2>","metadata":{}},{"cell_type":"code","source":"predictions = []\nlabels = []\n\nfor X, y in test_data.as_numpy_iterator():\n    y_pred = model.predict(X, verbose=0)\n    y_prediction = np.argmax(y_pred, axis=1)\n    predictions.extend(y_prediction)\n    labels.extend(y)\n    \npredictions = np.array(predictions)\nlabels = np.array(labels)\n\nprint(classification_report(labels, predictions, target_names=class_names))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2 style=\"color: white; background-color: dodgerblue; font-weight: bold; text-align: center; border:3px solid black;\">Confusion Matrix</h2>","metadata":{}},{"cell_type":"code","source":"cm = confusion_matrix(labels, predictions)\ncm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\ncm_df\nplt.figure(figsize=(10,6), dpi=300)\nsns.heatmap(cm_df, annot=True, cmap=\"Greys\", fmt=\".1f\")\nplt.title(\"Confusion Matrix\", fontweight=\"bold\")\nplt.xlabel(\"Predicted\", fontweight=\"bold\")\nplt.ylabel(\"True\", fontweight=\"bold\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<p style=\"color: black; background-color: lightsteelblue; border:2px solid black;\">\nLet's create a function that fetches a random image and displays a pie chart showing the probability distribution of which target value the image belongs to, represented as percentages. In this way, it will be seen which class the model gives the highest probability to.</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\"color: white; background-color: dodgerblue; font-weight: bold; text-align: center; border:3px solid black;\">Alzheimer Probability of a Random MRI from Test Data</h2>","metadata":{}},{"cell_type":"code","source":"def random_mri_prob_bringer(image_number=0):\n    \n    for images, _ in test_data.skip(5).take(1):\n        image = images[image_number]\n        pred = model.predict(tf.expand_dims(image, 0))[0]\n        \n    probs = list(tf.nn.softmax(pred).numpy()) \n    probs_dict = dict(zip(class_dist.keys(), probs))\n    \n    keys = list(probs_dict.keys())\n    values = list(probs_dict.values())\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, facecolor='black')\n    plt.subplots_adjust(wspace=0.4) \n    ax1.imshow(image)\n    ax1.set_title('Brain MRI', color=\"yellow\", fontweight=\"bold\", fontsize=16)\n    \n    edges = ['left', 'bottom', 'right', 'top']\n    edge_color = \"greenyellow\"\n    edge_width = 3\n    for edge in edges:\n        ax1.spines[edge].set_linewidth(edge_width)\n        ax1.spines[edge].set_edgecolor(edge_color)\n\n    plt.gca().axes.yaxis.set_ticklabels([])        \n    plt.gca().axes.xaxis.set_ticklabels([])\n\n    wedges, labels, autopct = ax2.pie(values, labels=keys,  autopct='%1.1f%%',\n        shadow=True, startangle=90, colors=colors, textprops={'fontsize': 8, \"fontweight\":\"bold\", \"color\":\"white\"},  wedgeprops=\n       {'edgecolor':'black'} , labeldistance=1.15)\n\n    for autotext in autopct:\n        autotext.set_color('black')\n\n    ax2.set_title('Dementia Probabilities', color=\"yellow\", fontweight=\"bold\", fontsize=16)\n    \nrand_img_no = np.random.randint(1, 32)\nrandom_mri_prob_bringer(image_number=rand_img_no)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<p style=\"color: black; background-color: lightsteelblue; border:2px solid black;\">\nNow, let's see the actual classes and predicted classes of these samples by bringing samples from our test data.</p>","metadata":{}},{"cell_type":"markdown","source":"<h2 style=\"color: white; background-color: dodgerblue; font-weight: bold; text-align: center; border:3px solid black;\">Comparing Predicted Classes with the Actual Classes from the Test Data</h2>","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 20), facecolor=\"gray\")\nfor images, labels in test_data.take(1):\n    for i in range(25):\n        ax = plt.subplot(5, 5, i + 1)\n        plt.imshow(images[i])\n        predictions = model.predict(tf.expand_dims(images[i], 0), verbose=0)\n        score = tf.nn.softmax(predictions[0])\n        if(class_names[labels[i]]==class_names[np.argmax(score)]):\n            plt.title(\"Actual: \"+class_names[labels[i]], color=\"aqua\", fontweight=\"bold\", fontsize=10)\n            plt.ylabel(\"Predicted: \"+class_names[np.argmax(score)], color=\"springgreen\", fontweight=\"bAold\", fontsize=10)\n            ok_text = plt.text(2, 10, \"OK \\u2714\", color=\"springgreen\", fontsize=14)\n            ok_text.set_bbox(dict(facecolor='lime', alpha=0.5))\n    \n        else:\n            plt.title(\"Actual: \"+class_names[labels[i]], color=\"aqua\", fontweight=\"bold\", fontsize=10)\n            plt.ylabel(\"Predicted: \"+class_names[np.argmax(score)], color=\"maroon\", fontweight=\"bold\", fontsize=10)\n            nok_text = plt.text(2, 10, \"NOK \\u2718\", color=\"red\", fontsize=14)\n            nok_text.set_bbox(dict(facecolor='maroon', alpha=0.5))\n        plt.gca().axes.yaxis.set_ticklabels([])        \n        plt.gca().axes.xaxis.set_ticklabels([])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3 style=\"color:tomato\">I hope you enjoyed it.<br><br>\nPlease upvote if you like this notebook. Any feedbacks are welcome. Thank you in advance!</h3>","metadata":{}}]}